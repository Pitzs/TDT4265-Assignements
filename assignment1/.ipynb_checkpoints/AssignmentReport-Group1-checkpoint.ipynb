{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a\n",
    "\n",
    "We want to proof that the gradient of the cost function\n",
    "\n",
    "\\begin{equation}\n",
    "    C^n(w) = - (y^n ln(\\hat{y})^n) + (1-y^n) ln(1-\\hat{y}^n))\n",
    "\\end{equation}\n",
    "\n",
    "is equal to its gradient.\n",
    "\n",
    "\\begin{equation} \n",
    "    \\frac{\\partial{C^n(w)}}{\\partial{w_i}} = -(y^n-\\hat{y}^n)x_i^n\n",
    "\\end{equation}\n",
    "\n",
    "**Hint**: To solve this, you have to use the chain rule. Also, you can use the fact that:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial{\\hat{y}^n}}{\\partial{w_i}} = x_i^n\\hat{y}^n(1-\\hat{y}^n)\n",
    "\\end{equation}\n",
    "\n",
    "### Resolution\n",
    "Here is presented the proof the this problem.\n",
    "\n",
    "\\begin{equation} \n",
    "    \\frac{\\partial{C^n(w)}}{\\partial{w_i}} = -(y^n\\frac{1}{\\hat{y}^n}\\frac{\\partial{\\hat{y}^n}}{\\partial{w_i}} + (1-y^n)(\\frac{1}{1-\\hat{y}^n})\\frac{\\partial{(1-\\hat{y}^n)}}{\\partial{w_i}})\n",
    "\\end{equation}\n",
    "\n",
    "applying the **\"Hint\"** to the previous equation, we obtain the following:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\frac{\\partial{C^n(w)}}{\\partial{w_i}} = -(y^n\\frac{1}{\\hat{y}^n}x_i^n\\hat{y}^n(1-\\hat{y}^n) + (\\frac{1-y^n}{1-\\hat{y}^n})(-x_i^n\\hat{y}^n(1-\\hat{y}^n)))\n",
    "\\end{equation}\n",
    "\n",
    "then with a simplification and group by the common factors, we will obtain:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\frac{\\partial{C^n(w)}}{\\partial{w_i}} = -(x_i^n(y^n-y^n\\hat{y}^n-\\hat{y}^n+y^n\\hat{y}^n))\n",
    "\\end{equation}\n",
    "\n",
    "which hereby proof the equation:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\frac{\\partial{C^n(w)}}{\\partial{w_i}} = -(y^n-\\hat{y}^n)x_i^n\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "![](task2b_binary_train_loss_no_early.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2b_binary_train_accuracy_no_early.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "With the following implementation, the training stops at **33** epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2e)\n",
    "We can notice that due to shufflin the spikes are now gone. This could suggest us that the spikes were caused by a bad recurrent batch that will worse the accuracy of the model. Now with the shuffling the training data of the bad batch is shuffled across the entire dataset.\n",
    "![](task2e_train_accuracy_shuffle_difference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "![](task3b_softmax_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "![](task3b_softmax_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "In the above image, we can notice that the accuracy for the validation set has reach a plateu while the training accuracy is still increasing. The accuracies are splitting apart across training steps, this will suggest us that the model started to overfit, which led an increase of training accuracy over the validation accuracy. In this way, the model has lost a little of generalization (\"*The model is memorizing not learning*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "FILL IN ANSWER\n",
    "\n",
    "![](task4b_softmax_weight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "FILL IN ANSWER\n",
    "\n",
    "![](task4c_l2_reg_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "![](task4d_l2_reg_norms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "FILL IN ANSWER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
